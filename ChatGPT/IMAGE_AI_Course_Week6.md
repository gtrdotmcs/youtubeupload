# Generative AI — Week 6  
**Topic:** Text-to-Image Generation (DALL·E, Stable Diffusion, MidJourney Alternatives)  
**Duration:** 2 hours (Weekend Study)  

---

## 🎯 Learning Objectives
By the end of this week, you will:
- Understand how text-to-image generation works.
- Learn about diffusion models and transformer-based approaches.
- Explore open-source tools for generating images from text.
- Create your first AI-generated images using free platforms.

---

## 📚 Topics Covered
1. **Introduction to Text-to-Image Models**
   - Brief history of image generation (GANs → Diffusion Models).
   - Difference between Stable Diffusion, DALL·E, and MidJourney.
   
2. **How Diffusion Models Work**
   - Noise addition and denoising.
   - Sampling methods.
   - Role of CLIP models in text-to-image.

3. **Popular Open-Source Text-to-Image Tools**
   - Stable Diffusion (AUTOMATIC1111, Diffusers library).
   - OpenAI’s DALL·E playground (free tier).
   - Hugging Face Spaces for image generation.

4. **Hands-On Practice**
   - Using Hugging Face Stable Diffusion WebUI.
   - Generating images with Google Colab for free.
   - Understanding prompt engineering for better results.

---

## 🌐 Open-Source Learning Links

### 📖 Theory
- [Stable Diffusion Explained — Hugging Face Blog](https://huggingface.co/blog/stable_diffusion)
- [Diffusion Models — Lil’Log](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)
- [DALL·E Overview — OpenAI](https://openai.com/research/dall-e)

### 💻 Practice
- [Hugging Face Diffusers GitHub Repo](https://github.com/huggingface/diffusers)
- [Free Stable Diffusion on Hugging Face Spaces](https://huggingface.co/spaces/stabilityai/stable-diffusion)
- [Stable Diffusion with Google Colab — Free Notebook](https://colab.research.google.com/github/CompVis/stable-diffusion/blob/main/notebooks/stable_diffusion.ipynb)
- [Prompt Engineering Guide](https://github.com/dair-ai/Prompt-Engineering-Guide)

---

## 📝 Activity Plan

### Hour 1 — Learn & Understand
- Read the Hugging Face blog post on Stable Diffusion.
- Watch a YouTube tutorial on text-to-image generation basics (e.g., Two Minute Papers or freeCodeCamp AI playlist).
- Study how prompts affect output quality.

### Hour 2 — Hands-On
- Launch the Hugging Face Stable Diffusion Space and generate at least 5 different images.
- Experiment with different prompt styles:
  - Descriptive (e.g., “a medieval castle at sunrise, ultra-detailed, 8k”).
  - Artistic (e.g., “Van Gogh style painting of a cyberpunk city”).
  - Minimalistic (e.g., “a red apple on a white background”).
- Save your best image outputs for future portfolio use.

---

## ✅ Progress Checklist
- [ ] Read about diffusion models from Hugging Face and Lil’Log.
- [ ] Explored DALL·E and Stable Diffusion features.
- [ ] Installed/used Hugging Face Spaces or Google Colab for image generation.
- [ ] Generated at least 5 AI images with varied prompts.
- [ ] Documented best results and prompt styles used.

---

## 🔜 Coming Next Week  
**Week 7:** Audio & Music Generation with AI (OpenAI Jukebox, Riffusion, MusicLM alternatives).  
You’ll learn how to turn text into music and explore AI-powered sound design tools.

---
