# Generative AI ‚Äî Week 8  
**Topic:** Video Generation with AI  
**Duration:** 2 hours (Weekend Study)  

---

## üéØ Learning Objectives
By the end of this week, you will:
- Understand how AI video generation works.
- Learn about text-to-video and image-to-video pipelines.
- Explore popular AI video generation tools (both free and open source).
- Create short AI-generated videos using different prompt styles.

---

## üìö Topics Covered
1. **Introduction to AI Video Generation**
   - Difference between image-to-video and text-to-video.
   - Applications in marketing, storytelling, gaming, and education.
   
2. **Types of AI Video Generation**
   - **Text-to-Video**: Create videos from natural language prompts.
   - **Image-to-Video**: Animate still images into motion.
   - **Video-to-Video**: Transform existing videos into a new style.

3. **Popular Tools & Models**
   - **Runway Gen-2** ‚Äî commercial but with free trial credits.
   - **Pika Labs** ‚Äî community-driven video generation platform.
   - **ModelScope Text2Video** ‚Äî open-source Hugging Face model.
   - **Stable Video Diffusion** ‚Äî extends Stable Diffusion for video.
   - **Kling AI** ‚Äî high-quality video from text.

4. **Hands-On Practice**
   - Generate short clips from text prompts.
   - Experiment with cinematic camera movements.
   - Use AI to create a looping background animation for a project.

---

## üåê Open-Source Learning Links

### üìñ Theory
- [Text-to-Video Synthesis Overview ‚Äî Papers with Code](https://paperswithcode.com/task/text-to-video-generation)
- [Stable Video Diffusion Blog (Stability AI)](https://stability.ai/news/stable-video-diffusion)
- [ModelScope Text2Video Overview](https://huggingface.co/damo-vilab/modelscope-text-to-video-synthesis)

### üíª Practice
- [Pika Labs (Free Account)](https://pika.art/)
- [Runway Gen-2](https://runwayml.com/)
- [ModelScope Text2Video Hugging Face Space](https://huggingface.co/spaces/damo-vilab/modelscope-text-to-video-synthesis)
- [Stable Video Diffusion Demo on Hugging Face](https://huggingface.co/spaces/guoyww/Animatediff)

---

## üìù Activity Plan

### Hour 1 ‚Äî Learn & Explore
- Read **Stable Video Diffusion** blog post to understand how frames are generated.
- Watch a YouTube demo comparing Pika Labs, Runway, and ModelScope.
- Explore the differences between commercial and open-source models.

### Hour 2 ‚Äî Hands-On
- Create **3 videos**:  
  1. A cinematic nature scene from text.  
  2. An animated loop for a background.  
  3. A creative fantasy or sci-fi clip.
- Save prompts, settings, and generated outputs.
- Test both a commercial platform (Pika Labs / Runway) and an open-source option (ModelScope / Stable Video Diffusion).

---

## ‚úÖ Progress Checklist
- [ ] Read about AI video generation basics.
- [ ] Compared at least 2 tools (one open-source, one commercial).
- [ ] Generated 3+ AI videos in different styles.
- [ ] Saved prompts, settings, and outputs.
- [ ] Identified a preferred tool for future projects.

---

## üîú Coming Next Week  
**Week 9:** Multimodal AI ‚Äî Combining Text, Image, Audio, and Video in a Single Workflow.  
You‚Äôll learn how to create projects where different AI-generated media elements work together.

---
