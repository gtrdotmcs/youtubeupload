# âœï¸ Generative AI Course â€” Week 3  
**Topic**: Text Generation with GPT-2  
**Duration**: ~2 hours  
**Goal**: Learn to use GPT-2 to generate creative text like poems, stories, and summaries using Hugging Face Transformers in Google Colab.

---

## ğŸªœ PART 1 â€“ Learn by Reading (~20â€“30 min)

### ğŸ“˜ 1.1 Understand How GPT-2 Generates Text

Quick primer:
- GPT-2 is an autoregressive model â€” it predicts the next word based on previous ones.
- You can adjust how much text it generates, how creative it is, and how random it should be.

ğŸ“– Read:
ğŸ”— [Hugging Face: Text Generation with Transformers](https://huggingface.co/transformers/task_summary.html#text-generation)

---

## ğŸªœ PART 2 â€“ Hands-On with Google Colab (~60â€“70 min)

### ğŸ§ª 2.1 Set Up GPT-2 in Google Colab

Open [Google Colab](https://colab.research.google.com) and run this to install:

`python !pip install transformers`

âœ… Load GPT-2 Model and Generate Text

```
from transformers import pipeline

generator = pipeline("text-generation", model="gpt2")

# Basic prompt
prompt = "The future of humanity lies"
result = generator(prompt, max_length=50, num_return_sequences=1)

print(result[0]['generated_text'])
```
---
ğŸ§ª 2.2 Try Creative Prompts

Try these:

- â€œShe opened the door and saw...â€

- â€œIn the year 2120, humans live on...â€

- â€œThe secret recipe for happiness is...â€

```
result = generator(prompt, 
                   max_length=60, 
                   num_return_sequences=2, 
                   temperature=0.8, 
                   top_p=0.95, 
                   do_sample=True)
```

ğŸ“˜ Documentation:
ğŸ”— [Text Generation Pipeline Options](https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.TextGenerationPipeline)
---

ğŸ§ª 2.3 Explore GPT-2 Variants (Optional)
Try a smaller or larger model:

- "gpt2-medium"

- "distilgpt2" (lighter, faster)
---

Update the model like this:
```
generator = pipeline("text-generation", model="distilgpt2")
```
---

âœ… Wrap-Up: Self Review

ğŸ§  Try answering:

- What are temperature, top_p, and do_sample used for?

- How does changing max_length affect the output?

- What surprised you about the modelâ€™s creativity or logic?

---

### Track

- ğŸ“‹ Week 3 Progress Checklist
    - [ ] Read Hugging Faceâ€™s text generation summary    
    - [ ] Installed Transformers and ran GPT-2 in Colab    
	- [ ] Generated text from 2â€“3 different prompts  
	- [ ] Experimented with `temperature`, `top_p`, or different model sizes  
	- [ ] Answered 3 self-review questions         
	
---

Coming Next:

Week 4 â€” Prompt Engineering Basics

In Week 4, youâ€™ll:

- Learn how to write better prompts for more accurate or creative results

- Understand few-shot prompting and role-based prompts

- Start building your own prompt library for different use-cases (e.g., summarizing, writing emails, storytelling)