
# Week 6 - Fine-tuning Basics

## 🎯 Learning Objectives
- Understand what fine-tuning is and when to use it.
- Learn the difference between full fine-tuning and parameter-efficient fine-tuning (PEFT).
- Explore open-source tools for fine-tuning models.

## 📚 Topics Covered
1. What is Fine-tuning?
2. Dataset preparation for fine-tuning.
3. Fine-tuning with Hugging Face `transformers`.
4. Introduction to PEFT (LoRA, adapters).
5. Cost and performance trade-offs.

## 🌐 Open-Source Learning Links
- [Hugging Face Fine-tuning Guide](https://huggingface.co/docs/transformers/training)
- [Google Colab for Fine-tuning](https://colab.research.google.com/)
- [PEFT Documentation](https://huggingface.co/docs/peft/index)
- [LoRA Paper](https://arxiv.org/abs/2106.09685)

## 📝 Activity Plan
1. Read Hugging Face's fine-tuning documentation.
2. Practice fine-tuning a small model (like DistilBERT) on a toy dataset in Google Colab.
3. Try PEFT with LoRA and compare with full fine-tuning.

## ✅ Progress Checklist
- [ ] I understand what fine-tuning is.
- [ ] I can prepare a dataset for fine-tuning.
- [ ] I can fine-tune a model in Colab.
- [ ] I can explain the advantages of LoRA.
- [ ] I have run at least one fine-tuning experiment.
